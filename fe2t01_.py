# -*- coding: utf-8 -*-
"""FE2T01 .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10uwU7QFzm36LjAeNVrtdmlbLkAn1CH-N

#Question

Which of the factors (Broad Phase of Flight, Purpose of Flight, Weather Condition) have the largest importance in the classification of severity of accidents?


Additional
- Checking location factor and performing classification to check the accuracy.

#Basic Libraries
"""

# Basic Libraries
import numpy as np
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt # We only need pyplot
sb.set() # set the default Seaborn style for graphics

"""#Basic Processing of Aviation dataset"""

# Dataset is now stored in a Pandas Dataframe
Avdata = pd.read_csv('AviationData.csv',engine='python')
Avdata.info()

#Remove NaN values
Avdata= Avdata.replace(np.nan,0)
Avdata

Avdata = Avdata.drop(['Event.Id','Accident.Number','Airport.Code','Airport.Name','Registration.Number',
                   'FAR.Description','Air.Carrier','Publication.Date'],axis=1)
Avdata

"""## Categorical Dataframe"""

CatData = pd.DataFrame(Avdata[['Investigation.Type','Aircraft.Damage','Aircraft.Category','Amateur.Built','Engine.Type','Schedule','Purpose.of.Flight','Weather.Condition','Broad.Phase.of.Flight','Report.Status']])

for x in CatData:
    CatData[x] = CatData[x].astype('category')
CatData.info()

"""# Exploratory Analysis on Categorical data"""

for x in CatData:
    sb.catplot(y = x, data = CatData, kind = "count", height = 8)

"""# Numerical Dataframe"""

NumData = pd.DataFrame(Avdata[['Latitude','Longitude', 'Number.of.Engines', 'Total.Fatal.Injuries', 'Total.Serious.Injuries','Total.Minor.Injuries','Total.Uninjured']])

NumData.info()

NumData.describe()

"""# Exploratory Analysis on Numerical dataframe"""

f, axes = plt.subplots(5, 3, figsize=(18, 20))
colors = ["r", "g", "b", "m", "c"]

count = 0
for var in NumData:
    #if(var == 'Latitude' or var == 'Longitude'):
        #continue
    sb.boxplot(NumData[var], orient = "h", color = colors[count%5], ax = axes[count%5,0])
    sb.distplot(NumData[var], color = colors[count%5], ax = axes[count%5,1])
    sb.violinplot(NumData[var], color = colors[count%5], ax = axes[count%5,2])
    count += 1

"""Pairplot"""

sb.pairplot(data = NumData)

"""Heat Map"""

f, axes = plt.subplots(1, 1, figsize=(15, 15))
sb.set(font_scale=2)

sb.heatmap(NumData.corr(), vmin = -1, vmax = 1, annot = True, fmt=".2f")
sb.set(font_scale=2)

"""Time Series of fatal injuries over the years"""

import operator # For dictionary sorting by value

Avdata["Event.Date"] = Avdata["Event.Date"].fillna('UNKNOWN');
Avdata["Event.Date"] = Avdata["Event.Date"].str.lower();

sorted_data = Avdata.sort_values(['Total.Fatal.Injuries'], ascending = False);

def get_year(event_date):
    
    if(len(event_date.strip()) == 0):
        return -1;
    
    dob_stripped = event_date.split('-');
    
    if(len(dob_stripped) != 3):
        return -2;
    
    return int(dob_stripped[0]);

rowc = 0
fatal_yearly = {}

for index, row in sorted_data.iterrows():
    year = get_year(row['Event.Date'])
    fatal = row['Total.Fatal.Injuries']
    
    if(year in fatal_yearly):
        fatal_yearly[year] = fatal_yearly[year] +  fatal
    else:
        fatal_yearly[year] = fatal
    
    rowc = rowc + 1

x_values = [];
y_values = [];
    
fatal_yearly_sorted = sorted(fatal_yearly.items(), key = operator.itemgetter(0));    
    
for k, v in fatal_yearly_sorted:
    # ignore before 1985 as they don't have anything significant
    if(k < 1985):
        continue;
    x_values.append(k);
    y_values.append(v);    
    
f, axes = plt.subplots(1, 1, figsize=(20,10))
plt.plot(x_values, y_values, label = 'Fatal Injuries', lw = 5, marker = 'o');

ax = plt.gca()
ax.get_xaxis().get_major_formatter().set_useOffset(False)

plt.xlabel('Year');
plt.ylabel('Fatal Injuries');
plt.legend(loc = 'upper left');
plt.title('Fatal Injuries since 1985')
    
plt.show()

"""# Classification of Severity of Accidents with various factors (Purpose of Flight, Weather Condition, Broad Phase of Flight)"""

from sklearn.model_selection import train_test_split
from sklearn.tree import export_graphviz
from sklearn.tree import DecisionTreeClassifier
import graphviz
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier

# Classification of 3 different variable
Avdata = pd.read_csv('AviationData.csv',engine='python')

FinalData = pd.DataFrame(Avdata[['Purpose.of.Flight','Weather.Condition','Broad.Phase.of.Flight']])
purpose=pd.DataFrame(Avdata['Purpose.of.Flight']) # purpose of flight dataframe
wctype=pd.DataFrame(Avdata['Weather.Condition']) # weather condition dataframe
phase=pd.DataFrame(Avdata['Broad.Phase.of.Flight']) # phase of flight dataframe
fatal = pd.DataFrame(Avdata['Total.Fatal.Injuries'])
#Scatterplots
sb.set(font_scale=1)
for i in FinalData:
    sb.catplot(x = 'Total.Fatal.Injuries', y = i, data = Avdata, orient = "h")

"""# Classification of Severity of Accidents with Purpose of Flight factor

Decision Tree
"""

Xvar_train, Xvar_test, yvar_train, yvar_test = train_test_split(fatal, purpose, test_size = 0.20)

# Create a Decision Tree Classifier object
purposedectree = DecisionTreeClassifier(max_depth = 4)

#Remove NaN values
Xvar_train = Xvar_train.replace(np.nan, '0')
yvar_train = yvar_train.replace(np.nan, '0')

# Train the Decision Tree Classifier model
purposedectree.fit(Xvar_train,yvar_train)

# Export the Decision Tree as a dot object
purposetreedot = export_graphviz(purposedectree,                                      # the model
                          feature_names = Xvar_train.columns,          # the features 
                          out_file = None,                              # output file
                          filled = True,                                # node colors
                          rounded = True,                               # make pretty
                          special_characters = True)                    # postscript

# Render using graphviz
graphviz.Source(purposetreedot)

"""Confusion Matrix"""

Xvar_test = Xvar_test.replace(np.nan, '0')
yvar_test = yvar_test.replace(np.nan, '0')

# Predict Legendary values corresponding to Total
yvar_train_pred = purposedectree.predict(Xvar_train)
yvar_test_pred = purposedectree.predict(Xvar_test)

# Check the Goodness of Fit (on Train Data)
print("Train Dataset")
print()
print("Classification Accuracy \t:", purposedectree.score(Xvar_train, yvar_train)*100)
print()
print()

# Check the Goodness of Fit (on Test Data)
print("Test Dataset")
print()
print("Classification Accuracy \t:", purposedectree.score(Xvar_test, yvar_test)*100)
print()
print()

# Plot the Confusion Matrix for Train and Test
f, axes = plt.subplots(1, 2, figsize=(30, 15))

sb.heatmap(confusion_matrix(yvar_train, yvar_train_pred), center=0.0,
           annot = True, fmt=".0f", annot_kws={"size": 18}, ax = axes[0])
sb.heatmap(confusion_matrix(yvar_test, yvar_test_pred), center=0.0,
           annot = True, fmt=".0f", annot_kws={"size": 18}, cmap=plt.cm.Blues, ax = axes[1])

"""#Classification of Severity of Accidents with Weather Condition factor"""

Xvar_train, Xvar_test, yvar_train, yvar_test = train_test_split(fatal, wctype, test_size = 0.20)

# Create a Decision Tree Classifier object
wcdectree = DecisionTreeClassifier(max_depth = 4)

#Remove NaN values
Xvar_train = Xvar_train.replace(np.nan, '0')
yvar_train = yvar_train.replace(np.nan, '0')

# Train the Decision Tree Classifier model
wcdectree.fit(Xvar_train,yvar_train)

# Export the Decision Tree as a dot object
wctreedot = export_graphviz(wcdectree,                                      # the model
                          feature_names = Xvar_train.columns,          # the features 
                          out_file = None,                              # output file
                          filled = True,                                # node colors
                          rounded = True,                               # make pretty
                          special_characters = True)                    # postscript

# Render using graphviz
graphviz.Source(wctreedot)

Xvar_test = Xvar_test.replace(np.nan, '0')
yvar_test = yvar_test.replace(np.nan, '0')

# Predict Legendary values corresponding to Total
yvar_train_pred = wcdectree.predict(Xvar_train)
yvar_test_pred = wcdectree.predict(Xvar_test)

# Check the Goodness of Fit (on Train Data)
print("Train Dataset")
print()
print("Classification Accuracy \t:", wcdectree.score(Xvar_train, yvar_train)*100)
print()
print()

# Check the Goodness of Fit (on Test Data)
print("Test Dataset")
print()
print("Classification Accuracy \t:", wcdectree.score(Xvar_test, yvar_test)*100)
print()
print()

# Plot the Confusion Matrix for Train and Test
f, axes = plt.subplots(1, 2, figsize=(10, 5))

sb.heatmap(confusion_matrix(yvar_train, yvar_train_pred), center=0.0,
           annot = True, fmt=".0f", annot_kws={"size": 18}, ax = axes[0])
sb.heatmap(confusion_matrix(yvar_test, yvar_test_pred), center=0.0,
           annot = True, fmt=".0f", annot_kws={"size": 18}, cmap=plt.cm.Blues, ax = axes[1])

"""# Classification of Severity of Accidents with Phase of Flight factor"""

Xvar_train, Xvar_test, yvar_train, yvar_test = train_test_split(fatal, phase, test_size = 0.20)

# Create a Decision Tree Classifier object
phasedectree = DecisionTreeClassifier(max_depth = 4)

#Remove NaN values
Xvar_train = Xvar_train.replace(np.nan, '0')
yvar_train = yvar_train.replace(np.nan, '0')

# Train the Decision Tree Classifier model
phasedectree.fit(Xvar_train,yvar_train)

# Export the Decision Tree as a dot object
phasetreedot = export_graphviz(phasedectree,                                      # the model
                          feature_names = Xvar_train.columns,          # the features 
                          out_file = None,                              # output file
                          filled = True,                                # node colors
                          rounded = True,                               # make pretty
                          special_characters = True)                    # postscript

# Render using graphviz
graphviz.Source(phasetreedot)

Xvar_test = Xvar_test.replace(np.nan, '0')
yvar_test = yvar_test.replace(np.nan, '0')

# Predict Legendary values corresponding to Total
yvar_train_pred = phasedectree.predict(Xvar_train)
yvar_test_pred = phasedectree.predict(Xvar_test)

# Check the Goodness of Fit (on Train Data)
print("Train Dataset")
print()
print("Classification Accuracy \t:", phasedectree.score(Xvar_train, yvar_train)*100)
print()
print()

# Check the Goodness of Fit (on Test Data)
print("Test Dataset")
print()
print("Classification Accuracy \t:", phasedectree.score(Xvar_test, yvar_test)*100)
print()
print()

# Plot the Confusion Matrix for Train and Test
f, axes = plt.subplots(1, 2, figsize=(30, 15))

sb.heatmap(confusion_matrix(yvar_train, yvar_train_pred), center=0.0,
           annot = True, fmt=".0f", annot_kws={"size": 18}, ax = axes[0])
sb.heatmap(confusion_matrix(yvar_test, yvar_test_pred), center=0.0,
           annot = True, fmt=".0f", annot_kws={"size": 18}, cmap=plt.cm.Blues, ax = axes[1])

"""Based on our initial hypothesis , we believe that these 3 factors would have a strong postive relation with total fatal injuries. However, it turns out only Weather condition has a strong classification accuracy. This might be due to the number of variables present.

#Classification of Severity of Accidents with Location factor

Preparing Data - Splitting US vs Non-US data
"""

Avdata_country = pd.DataFrame(Avdata[['Country', 'Total.Fatal.Injuries']])

#Replacing non-US data
Avdata_country.loc[Avdata_country['Country'] != 'United States', 'Country'] = 'Non-US'

sb.catplot(x = 'Total.Fatal.Injuries', y = 'Country', data = Avdata_country, orient = "h")

Avdata_country.dropna(inplace=True)

Xvar_train, Xvar_test, yvar_train, yvar_test = train_test_split(Avdata_country[['Total.Fatal.Injuries']], Avdata_country[['Country']], test_size = 0.20)

# Create a Decision Tree Classifier object
countrydectree = DecisionTreeClassifier(max_depth = 4)

#Remove NaN values
Xvar_train = Xvar_train.replace(np.nan, '0')
yvar_train = yvar_train.replace(np.nan, '0')

# Train the Decision Tree Classifier model
countrydectree.fit(Xvar_train,yvar_train)

# Export the Decision Tree as a dot object
purposetreedot = export_graphviz(countrydectree,                        # the model
                          feature_names = Xvar_train.columns,           # the features 
                          out_file = None,                              # output file
                          filled = True,                                # node colors
                          rounded = True,                               # make pretty
                          special_characters = True)                    # postscript

# Render using graphviz
graphviz.Source(purposetreedot)

#Remove NaN values
Xvar_test = Xvar_test.replace(np.nan, '0')
yvar_test = yvar_test.replace(np.nan, '0')

# Predict Legendary values corresponding to Total
yvar_train_pred = countrydectree.predict(Xvar_train)
yvar_test_pred = countrydectree.predict(Xvar_test)

# Check the Goodness of Fit (on Train Data)
print("Train Dataset")
print()
print("Classification Accuracy \t:", countrydectree.score(Xvar_train, yvar_train)*100)
print()
print()

# Check the Goodness of Fit (on Test Data)
print("Test Dataset")
print()
print("Classification Accuracy \t:", countrydectree.score(Xvar_test, yvar_test)*100)
print()
print()

# Plot the Confusion Matrix for Train and Test
f, axes = plt.subplots(1, 2, figsize=(30, 15))

sb.heatmap(confusion_matrix(yvar_train, yvar_train_pred), center=0.0,
           annot = True, fmt=".0f", annot_kws={"size": 18}, ax = axes[0])
sb.heatmap(confusion_matrix(yvar_test, yvar_test_pred), center=0.0,
           annot = True, fmt=".0f", annot_kws={"size": 18}, cmap=plt.cm.Blues, ax = axes[1])

"""#Country/Location"""

import plotly.express as px

# Data of Crashes visualise with ploty on google maps
Crash = pd.DataFrame(Avdata[['Investigation.Type','Event.Id','Location','Latitude','Longitude', 'Total.Fatal.Injuries']])

Crash["Total.Fatal.Injuries"] = Crash["Total.Fatal.Injuries"].fillna(0).astype(int);

# Get names of indexes for which total fatal injuries is 0
indexNames = Crash[ Crash['Total.Fatal.Injuries'] == 0 ].index
 
# Delete these row indexes from dataFrame
Crash.drop(indexNames , inplace=True)

fig = px.scatter_mapbox(Crash, lat="Latitude", lon="Longitude", hover_name="Location", hover_data=["Event.Id","Investigation.Type"],
                        color="Total.Fatal.Injuries", color_continuous_scale = 'Sunsetdark', zoom=1, height=600)

'''
Possible ways to change colour
color_discrete_map={"Europe": "red", "Asia": "green", "Americas": "blue"}
color_discrete_sequence=["red", "green", "blue", "goldenrod", "magenta"]
color_continuous_scale = px.colors.qualitative.Light24
'''

fig.update_layout(
    mapbox_style="white-bg",
    mapbox_layers=[
        {
            "below": 'traces',
            "sourcetype": "raster",
            "source": [
                "https://basemap.nationalmap.gov/arcgis/rest/services/USGSImageryOnly/MapServer/tile/{z}/{y}/{x}"
            ]
        }
      ])
fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
fig.show()

"""Colours of markers are coded according to the fatality/severity of the incidents.
Markers coloured light yellow and beige are those with few fatal injuries (below 50).
Markers coloured with more distinct colours are the anomalies, with significant amounts of fatal injuries. (For example, the orange marker has 115 fatal injuries and the pink marker has 228, etc.)

#Clustering and Anomaly detection with Location (Latitude, Longitude) and Total Fatal Injuries (3D Plot)
"""

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.cluster import KMeans

X = pd.DataFrame(Avdata[["Latitude", "Longitude", "Total.Fatal.Injuries"]]) 
X["Total.Fatal.Injuries"] = X["Total.Fatal.Injuries"].fillna(0);
X.fillna(X.mean(), inplace=True)

# Set "optimal" Number of Clusters
num_clust = 5

# Create Clustering Model using KMeans
kmeans = KMeans(n_clusters = num_clust)        

# Fit the Clustering Model on the Data
kmeans.fit(X)


# Predict the Cluster Labels
labels = kmeans.predict(X)

# Append Labels to the Data
X_labeled = X.copy()
X_labeled["Cluster"] = pd.Categorical(labels)

fig = plt.figure(figsize=(20, 20))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(X_labeled["Longitude"], X_labeled["Latitude"], X_labeled["Total.Fatal.Injuries"],
           linewidths=1, alpha=.7,
           edgecolor='k',
           s = 100,
           c= X_labeled["Cluster"])
plt.show()

from sklearn.neighbors import LocalOutlierFactor

# Guessing the Parameters for Neighborhood
num_neighbors = 85    # Number of Neighbors
cont_fraction = 0.01 # Fraction of Anomalies

# Create Anomaly Detection Model using LocalOutlierFactor
lof = LocalOutlierFactor(n_neighbors = num_neighbors, contamination = cont_fraction)

# Fit the Model on the Data and Predict Anomalies
lof.fit(X)

# Predict the Anomalies
labels = lof.fit_predict(X)

# Append Labels to the Data
X_labeled = X.copy()
X_labeled["Anomaly"] = pd.Categorical(labels)

fig = plt.figure(figsize=(20, 20))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(X_labeled["Longitude"], X_labeled["Latitude"], X_labeled["Total.Fatal.Injuries"],
           linewidths=1, alpha=.7,
           edgecolor='k',
           s = 100,
           c= X_labeled["Anomaly"])
plt.show()